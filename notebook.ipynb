{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# general libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import cloudpickle\n",
    "import pickle\n",
    "\n",
    "# NLP\n",
    "import gensim.downloader as api\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, classification_report, f1_score, hamming_loss\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# XGBoost, LightGBM\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>status</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>budget</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Released</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>825532764</td>\n",
       "      <td>148</td>\n",
       "      <td>False</td>\n",
       "      <td>/8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg</td>\n",
       "      <td>160000000</td>\n",
       "      <td>https://www.warnerbros.com/movies/inception</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>en</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Cobb, a skilled thief who commits corporate es...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>/oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg</td>\n",
       "      <td>Your mind is the scene of the crime.</td>\n",
       "      <td>Action, Science Fiction, Adventure</td>\n",
       "      <td>Legendary Pictures, Syncopy, Warner Bros. Pict...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, French, Japanese, Swahili</td>\n",
       "      <td>rescue, mission, dream, airplane, paris, franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>Released</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>701729206</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "      <td>/pbrkL804c8yAv3zBZR4QPEafpAR.jpg</td>\n",
       "      <td>165000000</td>\n",
       "      <td>http://www.interstellarmovie.net/</td>\n",
       "      <td>tt0816692</td>\n",
       "      <td>en</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>140.241</td>\n",
       "      <td>/gEU2QniE6E77NI6lCU6MxlNBvIx.jpg</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Adventure, Drama, Science Fiction</td>\n",
       "      <td>Legendary Pictures, Syncopy, Lynda Obst Produc...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>rescue, future, spacecraft, race against time,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>30619</td>\n",
       "      <td>Released</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>1004558444</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>/nMKdUUepR0i5zn0y1T4CsSB5chy.jpg</td>\n",
       "      <td>185000000</td>\n",
       "      <td>https://www.warnerbros.com/movies/dark-knight/</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Batman raises the stakes in his war on crime. ...</td>\n",
       "      <td>130.643</td>\n",
       "      <td>/qJ2tW6WMUDux911r6m7haRef0WH.jpg</td>\n",
       "      <td>Welcome to a world without rules.</td>\n",
       "      <td>Drama, Action, Crime, Thriller</td>\n",
       "      <td>DC Comics, Legendary Pictures, Syncopy, Isobel...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>joker, sadism, chaos, secret identity, crime f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>29815</td>\n",
       "      <td>Released</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>2923706026</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>237000000</td>\n",
       "      <td>https://www.avatar.com/movies/avatar</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>79.932</td>\n",
       "      <td>/kyeqWdyUXW608qlYkRqosgbbJyK.jpg</td>\n",
       "      <td>Enter the world of Pandora.</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>Dune Entertainment, Lightstorm Entertainment, ...</td>\n",
       "      <td>United States of America, United Kingdom</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>future, society, culture clash, space travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24428</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.710</td>\n",
       "      <td>29166</td>\n",
       "      <td>Released</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>1518815515</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg</td>\n",
       "      <td>220000000</td>\n",
       "      <td>https://www.marvel.com/movies/the-avengers</td>\n",
       "      <td>tt0848228</td>\n",
       "      <td>en</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>When an unexpected enemy emerges and threatens...</td>\n",
       "      <td>98.082</td>\n",
       "      <td>/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>Science Fiction, Action, Adventure</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English, Hindi, Russian</td>\n",
       "      <td>new york city, superhero, shield, based on com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            title  vote_average  vote_count    status release_date  \\\n",
       "0   27205        Inception         8.364       34495  Released   2010-07-15   \n",
       "1  157336     Interstellar         8.417       32571  Released   2014-11-05   \n",
       "2     155  The Dark Knight         8.512       30619  Released   2008-07-16   \n",
       "3   19995           Avatar         7.573       29815  Released   2009-12-15   \n",
       "4   24428     The Avengers         7.710       29166  Released   2012-04-25   \n",
       "\n",
       "      revenue  runtime  adult                     backdrop_path     budget  \\\n",
       "0   825532764      148  False  /8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg  160000000   \n",
       "1   701729206      169  False  /pbrkL804c8yAv3zBZR4QPEafpAR.jpg  165000000   \n",
       "2  1004558444      152  False  /nMKdUUepR0i5zn0y1T4CsSB5chy.jpg  185000000   \n",
       "3  2923706026      162  False  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg  237000000   \n",
       "4  1518815515      143  False  /9BBTo63ANSmhC4e6r62OJFuK2GL.jpg  220000000   \n",
       "\n",
       "                                         homepage    imdb_id  \\\n",
       "0     https://www.warnerbros.com/movies/inception  tt1375666   \n",
       "1               http://www.interstellarmovie.net/  tt0816692   \n",
       "2  https://www.warnerbros.com/movies/dark-knight/  tt0468569   \n",
       "3            https://www.avatar.com/movies/avatar  tt0499549   \n",
       "4      https://www.marvel.com/movies/the-avengers  tt0848228   \n",
       "\n",
       "  original_language   original_title  \\\n",
       "0                en        Inception   \n",
       "1                en     Interstellar   \n",
       "2                en  The Dark Knight   \n",
       "3                en           Avatar   \n",
       "4                en     The Avengers   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  Cobb, a skilled thief who commits corporate es...      83.952   \n",
       "1  The adventures of a group of explorers who mak...     140.241   \n",
       "2  Batman raises the stakes in his war on crime. ...     130.643   \n",
       "3  In the 22nd century, a paraplegic Marine is di...      79.932   \n",
       "4  When an unexpected enemy emerges and threatens...      98.082   \n",
       "\n",
       "                        poster_path  \\\n",
       "0  /oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg   \n",
       "1  /gEU2QniE6E77NI6lCU6MxlNBvIx.jpg   \n",
       "2  /qJ2tW6WMUDux911r6m7haRef0WH.jpg   \n",
       "3  /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
       "4   /RYMX2wcKCBAr24UyPD7xwmjaTn.jpg   \n",
       "\n",
       "                                             tagline  \\\n",
       "0               Your mind is the scene of the crime.   \n",
       "1  Mankind was born on Earth. It was never meant ...   \n",
       "2                  Welcome to a world without rules.   \n",
       "3                        Enter the world of Pandora.   \n",
       "4                            Some assembly required.   \n",
       "\n",
       "                                        genres  \\\n",
       "0           Action, Science Fiction, Adventure   \n",
       "1            Adventure, Drama, Science Fiction   \n",
       "2               Drama, Action, Crime, Thriller   \n",
       "3  Action, Adventure, Fantasy, Science Fiction   \n",
       "4           Science Fiction, Action, Adventure   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  Legendary Pictures, Syncopy, Warner Bros. Pict...   \n",
       "1  Legendary Pictures, Syncopy, Lynda Obst Produc...   \n",
       "2  DC Comics, Legendary Pictures, Syncopy, Isobel...   \n",
       "3  Dune Entertainment, Lightstorm Entertainment, ...   \n",
       "4                                     Marvel Studios   \n",
       "\n",
       "                       production_countries  \\\n",
       "0  United Kingdom, United States of America   \n",
       "1  United Kingdom, United States of America   \n",
       "2  United Kingdom, United States of America   \n",
       "3  United States of America, United Kingdom   \n",
       "4                  United States of America   \n",
       "\n",
       "                     spoken_languages  \\\n",
       "0  English, French, Japanese, Swahili   \n",
       "1                             English   \n",
       "2                   English, Mandarin   \n",
       "3                    English, Spanish   \n",
       "4             English, Hindi, Russian   \n",
       "\n",
       "                                            keywords  \n",
       "0  rescue, mission, dream, airplane, paris, franc...  \n",
       "1  rescue, future, spacecraft, race against time,...  \n",
       "2  joker, sadism, chaos, secret identity, crime f...  \n",
       "3  future, society, culture clash, space travel, ...  \n",
       "4  new york city, superhero, shield, based on com...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "tmdb = pd.read_csv('../../Downloads/raw_tmdb.csv')\n",
    "tmdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed movies that are unreleased\n",
    "tmdb = tmdb[tmdb['status'] == 'Released']\n",
    "# remove movies that do not have a description\n",
    "tmdb = tmdb[tmdb['overview'].notna()]\n",
    "# change dates to pandas datetime format\n",
    "tmdb['release_date'] = pd.to_datetime(tmdb['release_date'])\n",
    "# original language is english\n",
    "tmdb = tmdb[tmdb['original_language'] == 'en']\n",
    "# drop columns\n",
    "tmdb = tmdb.drop(columns = ['backdrop_path', 'homepage', 'original_title', 'poster_path', 'tagline', 'spoken_languages', 'original_language', 'status'])\n",
    "# insert release_year\n",
    "years = tmdb['release_date'].dt.year\n",
    "tmdb.insert(4, 'release_year', years)\n",
    "# insert profit\n",
    "tmdb.insert(9, 'profit', tmdb['revenue'] - tmdb['budget'])\n",
    "# remove 0 budget movies\n",
    "tmdb = tmdb[tmdb['budget'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop movies without title\n",
    "tmdb = tmdb[tmdb['title'].notna()]\n",
    "# drop movies without runtimes\n",
    "tmdb = tmdb[tmdb['runtime'] != 0]\n",
    "# drop movies without release date\n",
    "tmdb = tmdb[tmdb['release_date'].notna()]\n",
    "# convert release_year to int\n",
    "tmdb['release_year'] = tmdb['release_year'].astype(int)\n",
    "# rename popularity to tmdb_popularity\n",
    "tmdb = tmdb.rename(columns={'popularity': 'tmdb_popularity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "tmdb = tmdb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only non-zero revenues and export csv\n",
    "tmdb_rev = tmdb[tmdb['revenue'] != 0]\n",
    "tmdb_rev.to_csv('./data/tmdb_rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d3af30bda34c3f867a50bc800a887c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/286 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 98283\n",
      "[LightGBM] [Info] Number of data points in the train set: 7297, number of used features: 386\n",
      "[LightGBM] [Info] Start training from score 69626749.761683\n",
      "mean absolute error (mae): 55131345.73391748\n",
      "r-squared (r²): 0.519923223320369\n",
      "✅ model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "# load dataset and clean missing values\n",
    "df = pd.read_csv('./data/tmdb_rev.csv')\n",
    "df = df.dropna(subset=['overview', 'budget', 'release_year', 'revenue', 'title'])\n",
    "df['overview'] = df['overview'].fillna(\"\")\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "df['release_year'] = df['release_year'].fillna(0)\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "\n",
    "# load pre-trained bert model to generate embeddings\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "overview_embeddings = bert.encode(df['overview'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# prepare features and target\n",
    "X = np.hstack([\n",
    "    overview_embeddings,\n",
    "    df[['budget', 'release_year']].values\n",
    "])\n",
    "y = df['revenue'].values\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the lightgbm model\n",
    "model = LGBMRegressor(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# custom accuracy metric\n",
    "def calculate_accuracy(y_true, y_pred, tolerance=0.1):\n",
    "    correct_predictions = np.abs(y_true - y_pred) <= (tolerance * y_true)\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "    return accuracy\n",
    "\n",
    "# evaluate model performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print results\n",
    "print(f\"mean absolute error (mae): {mae}\")\n",
    "print(f\"r-squared (r²): {r2}\")\n",
    "\n",
    "# save model and embeddings\n",
    "with open(\"models/revenue_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(\"models/bert_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bert, f)\n",
    "\n",
    "# save movie reference and embeddings\n",
    "df[['title', 'overview']].to_csv(\"models/title_reference.csv\", index=False)\n",
    "np.save(\"models/overview_embeddings.npy\", overview_embeddings)\n",
    "\n",
    "# print completion message\n",
    "print(\"✅ model training complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lasyayadlapati/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading glove embeddings...\n",
      "training model...\n",
      "\n",
      "accuracy: 0.6569506726457399\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Flop       0.78      0.87      0.82       823\n",
      "     Average       0.46      0.55      0.50       440\n",
      "         Hit       0.22      0.03      0.05       190\n",
      " Blockbuster       0.65      0.63      0.64       331\n",
      "\n",
      "    accuracy                           0.66      1784\n",
      "   macro avg       0.53      0.52      0.50      1784\n",
      "weighted avg       0.62      0.66      0.63      1784\n",
      "\n",
      "✅ model saved using cloudpickle at models/final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and filter out movies with zero budget\n",
    "df = pd.read_csv('./data/tmdb_rev.csv')\n",
    "df = df[df[\"budget\"] != 0]\n",
    "\n",
    "# remove rows where 'genres' column isn't a string\n",
    "df = df[df['genres'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# convert genre strings into lists of genres\n",
    "list_genres = df[\"genres\"].dropna().apply(lambda x: [g.strip() for g in x.split(\",\")])\n",
    "\n",
    "# collect unique genres from the genre lists\n",
    "unique_genres = set(genre for sublist in list_genres for genre in sublist)\n",
    "\n",
    "# sort and select a few key genres\n",
    "selected_genres = ['Action', 'Adventure', 'Comedy', 'Crime', 'Drama', 'Fantasy', 'Romance', 'Science Fiction', 'Thriller']\n",
    "df['genre_list'] = df['genres'].apply(lambda x: [g.strip() for g in x.split(',') if g.strip() in selected_genres])\n",
    "\n",
    "# download the sentiment analysis model\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# ---------- Load GloVe ----------\n",
    "print(\"loading glove embeddings...\")\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# ---------- Custom Transformers ----------\n",
    "class ListToWordsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "class TextToWordList(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.fillna(\"\").apply(lambda x: x.lower().split())\n",
    "\n",
    "class PretrainedEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, vector_size):\n",
    "        self.model = model\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        result = []\n",
    "        for item in X:\n",
    "            vectors = [self.model[word] for word in item if word in self.model]\n",
    "            avg_vector = np.mean(vectors, axis=0) if vectors else np.zeros(self.vector_size)\n",
    "            result.append(avg_vector)\n",
    "        return np.array(result)\n",
    "\n",
    "class SentimentExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.fillna(\"\").apply(lambda x: self.analyzer.polarity_scores(x)['compound']).to_frame()\n",
    "\n",
    "# ---------- Data Preparation ----------\n",
    "# categorize revenue into groups like flop, average, hit, blockbuster\n",
    "revenue_bins = [0, 1e7, 5e7, 1e8, np.inf]\n",
    "bin_labels = [0, 1, 2, 3]\n",
    "df['revenue_class'] = pd.cut(df['revenue'], bins=revenue_bins, labels=bin_labels)\n",
    "df = df.dropna(subset=['revenue_class'])\n",
    "y = df['revenue_class'].astype(int)\n",
    "\n",
    "# select features for training\n",
    "X = df[['runtime', 'adult', 'budget', 'overview', 'genre_list', 'production_companies', 'production_countries']]\n",
    "\n",
    "# ---------- Train/Test Split ----------\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ---------- GloVe & Sentiment Pipelines ----------\n",
    "# pipeline for transforming overview text to GloVe embeddings\n",
    "overview_glove = Pipeline([\n",
    "    ('text_to_words', TextToWordList()),\n",
    "    ('glove_embed', PretrainedEmbeddingTransformer(glove_model, 100))\n",
    "])\n",
    "\n",
    "# pipeline for transforming genre lists to GloVe embeddings\n",
    "genre_glove = Pipeline([\n",
    "    ('list_to_words', ListToWordsTransformer()),\n",
    "    ('glove_embed', PretrainedEmbeddingTransformer(glove_model, 100))\n",
    "])\n",
    "\n",
    "# pipeline for sentiment analysis of overview text\n",
    "sentiment_pipe = Pipeline([\n",
    "    ('sentiment', SentimentExtractor())\n",
    "])\n",
    "\n",
    "# ---------- Multi-hot Pipelines for company/country ----------\n",
    "# custom transformer for multi-hot encoding lists (companies/countries)\n",
    "class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        parsed = X.apply(self._safe_parse)\n",
    "        self.mlb.fit(parsed)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        parsed = X.apply(self._safe_parse)\n",
    "        return self.mlb.transform(parsed)\n",
    "\n",
    "    def _safe_parse(self, x):\n",
    "        if isinstance(x, list):\n",
    "            return x\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                return ast.literal_eval(x)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return [item.strip() for item in x.split(\",\") if item.strip()]\n",
    "        return []\n",
    "\n",
    "# pipelines for production companies and countries\n",
    "company_pipe = Pipeline([\n",
    "    ('mlb', MultiLabelBinarizerTransformer())\n",
    "])\n",
    "\n",
    "country_pipe = Pipeline([\n",
    "    ('mlb', MultiLabelBinarizerTransformer())\n",
    "])\n",
    "\n",
    "# ---------- Preprocessing ColumnTransformer ----------\n",
    "# column transformer to apply different preprocessing steps to each feature\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('runtime', StandardScaler(), ['runtime']),\n",
    "    ('budget', StandardScaler(), ['budget']),\n",
    "    ('adult', OneHotEncoder(drop='if_binary'), ['adult']),\n",
    "    ('overview_glove', overview_glove, 'overview'),\n",
    "    ('genre_glove', genre_glove, 'genre_list'),\n",
    "    ('companies', company_pipe, 'production_companies'),\n",
    "    ('countries', country_pipe, 'production_countries'),\n",
    "    ('sentiment', sentiment_pipe, 'overview')\n",
    "])\n",
    "\n",
    "# ---------- Full Model Pipeline ----------\n",
    "# full pipeline: preprocessing followed by XGBoost classifier\n",
    "model = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------- Train & Evaluate ----------\n",
    "# train the model and evaluate its performance\n",
    "print(\"training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the model evaluation results\n",
    "print(\"\\naccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nclassification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Flop', 'Average', 'Hit', 'Blockbuster']))\n",
    "\n",
    "# ---------- Save Model ----------\n",
    "# save the trained model using cloudpickle\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "with open(\"models/final_model.pkl\", \"wb\") as f:\n",
    "    cloudpickle.dump(model, f)\n",
    "\n",
    "print(\"✅ model saved using cloudpickle at models/final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue Accuracy:  0.832201670717976\n",
      "\n",
      "💰 Revenue Prediction Results:\n",
      "MAE: 51435013.073124126\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load and Clean Data ----------\n",
    "df = pd.read_csv('./data/tmdb_rev.csv')\n",
    "\n",
    "# remove movies with zero budget\n",
    "df = df[df[\"budget\"] != 0]\n",
    "\n",
    "# filter rows where genres column is not a string\n",
    "df = df[df['genres'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# parse genre strings into lists\n",
    "selected_genres = ['Action', 'Adventure', 'Comedy', 'Crime', 'Drama', 'Fantasy', 'Romance', 'Science Fiction', 'Thriller']\n",
    "df['genre_list'] = df['genres'].apply(lambda x: [g.strip() for g in x.split(',') if g.strip() in selected_genres])\n",
    "\n",
    "# ---------- Create Multi-Label Genre Matrix ----------\n",
    "mlb = MultiLabelBinarizer(classes=selected_genres)\n",
    "Y_genres = mlb.fit_transform(df['genre_list'])\n",
    "\n",
    "# ---------- Extract Sentiment Feature From Overview ----------\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['overview'].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])\n",
    "\n",
    "# ---------- Create TF-IDF of Movie Synopses ----------\n",
    "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_synopsis = tfidf.fit_transform(df['overview']).toarray()\n",
    "\n",
    "# ---------- Stage 1: Genre Prediction ---------- \n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_synopsis, Y_genres, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a multi-output classifier for genre prediction\n",
    "genre_model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "genre_model.fit(X_train_g, y_train_g)\n",
    "\n",
    "# predict genres on the whole dataset (used in Stage 2)\n",
    "genre_preds = genre_model.predict(X_synopsis)\n",
    "\n",
    "# ---------- Combine Features for Revenue Prediction ----------\n",
    "metadata_cols = ['budget', 'release_year']\n",
    "metadata = df[metadata_cols].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_metadata = scaler.fit_transform(metadata)\n",
    "\n",
    "X_emotion = df[['sentiment']].values  # use sentiment feature for now\n",
    "X_combined = np.hstack([genre_preds, X_emotion, X_synopsis, X_metadata])\n",
    "\n",
    "# ---------- Stage 2: Revenue Prediction ---------- \n",
    "y_revenue = df['revenue'].values\n",
    "y_log = np.log1p(y_revenue)  # apply log transformation to revenue\n",
    "\n",
    "X_train_rev, X_test_rev, y_train_rev, y_test_rev = train_test_split(X_combined, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# train a model to predict revenue\n",
    "revenue_model = XGBRegressor()\n",
    "revenue_model.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# make predictions and evaluate\n",
    "log_preds = revenue_model.predict(X_test_rev)\n",
    "revenue_preds = np.expm1(log_preds)\n",
    "revenue_true = np.expm1(y_test_rev)\n",
    "\n",
    "# evaluate revenue prediction accuracy\n",
    "revenue_acc = revenue_model.score(X_test_rev, y_test_rev)\n",
    "print(\"Revenue Accuracy: \", revenue_acc)\n",
    "print(\"\\n💰 Revenue Prediction Results:\")\n",
    "print(\"MAE:\", mean_absolute_error(revenue_true, revenue_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
